{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\lubac\\ACQuA.csv\", header=0)\n",
    "df_french = pd.read_csv(r\"C:\\Users\\lubac\\french_df.csv\", header=0, index_col=0)\n",
    "df_russian = pd.read_csv(r\"C:\\Users\\lubac\\russian_df.csv\", header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_fr_ru = pd.concat([df, df_french, df_russian], ignore_index=True)\n",
    "df_en_fr_ru = df_en_fr_ru.drop(columns=['id',\n",
    "                      'domain',\n",
    "                      'it_1_confidence',\n",
    "                      'it_2_confidence',\n",
    "                      'better_count',\n",
    "                      'worse_count',\n",
    "                      'none_count',\n",
    "                      'most_frequent_count',\n",
    "                      'it_1_judgments', \n",
    "                      'it_2_judgments', \n",
    "                      'sentence_html', \n",
    "                      'judgments', \n",
    "                      'confidence', \n",
    "                      'dconfidence'])\n",
    "\n",
    "df_en_fr_ru = df_en_fr_ru.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2076ca373ac4f53ab242266b0a315a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lubac\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lubac\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728c6a422b844515b2dcc56c43506859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "#Sentences we want sentence embeddings for\n",
    "sentences = ['Привет! Как твои дела?',\n",
    "             'А правда, что 42 твое любимое число?',\n",
    "             'bonjour, mon nom est Paul']\n",
    "#Load AutoModel from huggingface model repository\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "#Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=24, return_tensors='pt')\n",
    "#Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "#Perform pooling. In this case, mean pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings(sentences):\n",
    "  encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=24, return_tensors='pt')\n",
    "  with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "  sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "  return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21554/21554 [16:17<00:00, 22.05it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "objects_a, objects_b, sentences, labels = df_en_fr_ru.object_a.to_list(), df_en_fr_ru.object_b.to_list(), df_en_fr_ru.sentence.to_list(), df_en_fr_ru.most_frequent_label.to_list()\n",
    "\n",
    "label_d = {'WORSE': 0, 'BETTER': 1, 'NONE': 2}\n",
    "\n",
    "prepared = []\n",
    "labels_new = []\n",
    "\n",
    "for i in tqdm(range(len(objects_a))):\n",
    "  text = 'OBJECT1 ' + objects_a[i] + ' OBJECT2 ' + objects_b[i] + ' SENTENCE ' + sentences[i]\n",
    "  prepared.append(embeddings(text)[0].numpy())\n",
    "  labels_new.append(label_d[labels[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m prepared \u001b[39m=\u001b[39m prepared\u001b[39m.\u001b[39;49mreshape(prepared\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "prepared = prepared.reshape(prepared.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(prepared, labels_new, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, recall_score, precision_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline, FeatureUnion\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lubac\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       WORSE       0.22      0.01      0.03       343\n",
      "      BETTER       0.50      0.18      0.27       824\n",
      "        NONE       0.76      0.96      0.85      3144\n",
      "\n",
      "    accuracy                           0.74      4311\n",
      "   macro avg       0.49      0.39      0.38      4311\n",
      "weighted avg       0.66      0.74      0.67      4311\n",
      "\n",
      "AdaBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       WORSE       0.19      0.01      0.03       343\n",
      "      BETTER       0.50      0.08      0.13       824\n",
      "        NONE       0.74      0.98      0.84      3144\n",
      "\n",
      "    accuracy                           0.73      4311\n",
      "   macro avg       0.48      0.36      0.33      4311\n",
      "weighted avg       0.65      0.73      0.64      4311\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lubac\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (linear)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       WORSE       0.21      0.01      0.02       343\n",
      "      BETTER       0.52      0.18      0.27       824\n",
      "        NONE       0.76      0.97      0.85      3144\n",
      "\n",
      "    accuracy                           0.74      4311\n",
      "   macro avg       0.50      0.38      0.38      4311\n",
      "weighted avg       0.67      0.74      0.67      4311\n",
      "\n",
      "Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       WORSE       0.11      0.10      0.11       343\n",
      "      BETTER       0.33      0.32      0.32       824\n",
      "        NONE       0.78      0.79      0.79      3144\n",
      "\n",
      "    accuracy                           0.65      4311\n",
      "   macro avg       0.41      0.40      0.40      4311\n",
      "weighted avg       0.64      0.65      0.64      4311\n",
      "\n",
      "SGD Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       WORSE       0.29      0.01      0.01       343\n",
      "      BETTER       0.53      0.15      0.23       824\n",
      "        NONE       0.75      0.97      0.85      3144\n",
      "\n",
      "    accuracy                           0.74      4311\n",
      "   macro avg       0.52      0.38      0.36      4311\n",
      "weighted avg       0.67      0.74      0.66      4311\n",
      "\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       WORSE       0.18      0.01      0.02       343\n",
      "      BETTER       0.55      0.17      0.26       824\n",
      "        NONE       0.76      0.97      0.85      3144\n",
      "\n",
      "    accuracy                           0.74      4311\n",
      "   macro avg       0.50      0.39      0.38      4311\n",
      "weighted avg       0.67      0.74      0.67      4311\n",
      "\n",
      "Extra Trees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       WORSE       0.20      0.02      0.04       343\n",
      "      BETTER       0.52      0.18      0.27       824\n",
      "        NONE       0.76      0.96      0.85      3144\n",
      "\n",
      "    accuracy                           0.74      4311\n",
      "   macro avg       0.49      0.39      0.39      4311\n",
      "weighted avg       0.67      0.74      0.67      4311\n",
      "\n",
      "k-Neighbors\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       WORSE       0.17      0.09      0.12       343\n",
      "      BETTER       0.38      0.30      0.33       824\n",
      "        NONE       0.79      0.88      0.83      3144\n",
      "\n",
      "    accuracy                           0.70      4311\n",
      "   macro avg       0.45      0.42      0.43      4311\n",
      "weighted avg       0.66      0.70      0.68      4311\n",
      "\n",
      "SVM (radial basis function)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       WORSE       0.00      0.00      0.00       343\n",
      "      BETTER       0.73      0.04      0.07       824\n",
      "        NONE       0.73      1.00      0.85      3144\n",
      "\n",
      "    accuracy                           0.73      4311\n",
      "   macro avg       0.49      0.34      0.31      4311\n",
      "weighted avg       0.68      0.73      0.63      4311\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lubac\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\lubac\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\lubac\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (polynomial)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       WORSE       0.00      0.00      0.00       343\n",
      "      BETTER       0.65      0.06      0.11       824\n",
      "        NONE       0.74      1.00      0.85      3144\n",
      "\n",
      "    accuracy                           0.74      4311\n",
      "   macro avg       0.46      0.35      0.32      4311\n",
      "weighted avg       0.66      0.74      0.64      4311\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lubac\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\lubac\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\lubac\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (sigmoid)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       WORSE       0.00      0.00      0.00       343\n",
      "      BETTER       0.21      0.06      0.10       824\n",
      "        NONE       0.73      0.94      0.82      3144\n",
      "\n",
      "    accuracy                           0.70      4311\n",
      "   macro avg       0.31      0.33      0.31      4311\n",
      "weighted avg       0.57      0.70      0.62      4311\n",
      "\n",
      "Majority Class Baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       WORSE       0.00      0.00      0.00       343\n",
      "      BETTER       0.00      0.00      0.00       824\n",
      "        NONE       0.73      1.00      0.84      3144\n",
      "\n",
      "    accuracy                           0.73      4311\n",
      "   macro avg       0.24      0.33      0.28      4311\n",
      "weighted avg       0.53      0.73      0.62      4311\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lubac\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\lubac\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\lubac\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       WORSE       0.23      0.02      0.04       343\n",
      "      BETTER       0.54      0.24      0.33       824\n",
      "        NONE       0.77      0.96      0.86      3144\n",
      "\n",
      "    accuracy                           0.75      4311\n",
      "   macro avg       0.51      0.41      0.41      4311\n",
      "weighted avg       0.69      0.75      0.69      4311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [('Logistic Regression', LogisticRegression()),\n",
    "               ('AdaBoost', AdaBoostClassifier()), ('SVM (linear)', LinearSVC()),\n",
    "               ('Decision Tree', DecisionTreeClassifier()),\n",
    "               ('SGD Classifier', SGDClassifier()), ('Random Forest', RandomForestClassifier()), ('Extra Trees', ExtraTreesClassifier()), ('k-Neighbors', KNeighborsClassifier()),\n",
    "               ('SVM (radial basis function)', SVC(kernel='rbf')), ('SVM (polynomial)', SVC(kernel='poly')), ('SVM (sigmoid)', SVC(kernel='sigmoid')),\n",
    "               #('Multinomial NB', MultinomialNB()), \n",
    "               ('Majority Class Baseline', DummyClassifier(strategy='most_frequent')), ('XGBoost', XGBClassifier(n_jobs=8, n_estimators=1000))\n",
    "               ]\n",
    "\n",
    "\n",
    "for name, classifier in classifiers:\n",
    "    fitted = classifier.fit(X_train, y_train)\n",
    "    predicted = fitted.predict(X_test)\n",
    "    print(name)\n",
    "    print(classification_report(y_test, predicted, labels = [0, 1, 2], target_names=['WORSE', 'BETTER', 'NONE']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
